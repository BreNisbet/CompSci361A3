{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "homeless-valentine",
   "metadata": {},
   "source": [
    "# 361 A3\n",
    "Brendan Nisbet <br>\n",
    "bnis814<br>\n",
    "332343474"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "after-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "from collections import Counter\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-discharge",
   "metadata": {},
   "source": [
    "### Get top 1000 most common words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-olive",
   "metadata": {},
   "source": [
    "I store the top both as just a list of words that I can use as headers later and a dictionary so I can look up specific words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lyric-equality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'of', 'and', 'a', 'in'] ... ['useful', 'symbiont', 'full-orf', 'individual', '29']\n",
      "{'the': 46507, 'of': 36531, 'and': 24296, 'a': 16548, 'in': 16082, 'to': 12778, 'that': 7743, 'is': 7540, 'genes': 6396, 'with': 6185, 'for': 5830, 'sequence': 5183, 'gene': 5097, 'from': 5081, 'are': 4901, 'was': 4488, 'by': 4317, 'genome': 3728, 'protein': 3493, 'were': 3428, 'as': 3291, 'this': 3136, 'which': 3048, 'an': 3046, 'we': 3030, 'have': 2757, 'amino': 2629, 'two': 2588, 'these': 2549, 'proteins': 2518, 'sequences': 2429, 'acid': 2127, 'human': 2049, 'has': 2048, 'be': 2036, 'dna': 1992, 'been': 1914, 'other': 1843, 'on': 1823, 'at': 1808, 'analysis': 1792, 'cdna': 1773, 'identified': 1645, 'region': 1545, 'or': 1410, 'found': 1384, 'not': 1353, 'chromosome': 1349, 'expression': 1289, 'also': 1250, 'its': 1211, 'between': 1206, 'contains': 1187, 'b': 1187, 'encoding': 1186, 'one': 1165, 'but': 1165, 'cells': 1161, 'three': 1139, 'all': 1139, 'complete': 1129, 'it': 1117, 'sequenced': 1115, 'species': 1101, 'c': 1099, 'coli': 1090, 'predicted': 1042, 'cell': 1025, 'isolated': 1014, 'determined': 1009, 'mouse': 1001, 'both': 993, 'bp': 975, 'nucleotide': 975, 'may': 956, 'regions': 940, 'genomic': 940, 'strain': 928, 'most': 916, 'acids': 912, 'reading': 897, 'expressed': 894, 's': 890, 'than': 881, 'family': 876, 'their': 874, 'coding': 873, 'conserved': 872, 'open': 851, 'previously': 851, 'similar': 850, 'only': 837, 'mrna': 836, 'similarity': 821, 'revealed': 811, 'clones': 807, 'cloned': 800, 'known': 794, 'related': 792, 'including': 791, 'more': 785, 'showed': 771, 'involved': 765, 'molecular': 764, 'homology': 759, 'here': 751, 'using': 751, 'those': 749, 'function': 743, 'into': 737, 'no': 727, 'enzyme': 722, 'new': 716, 'activity': 714, 'different': 711, 'residues': 706, 'putative': 705, 'many': 695, 'high': 692, 'present': 691, 'several': 665, 'within': 663, 'rna': 648, 'structure': 644, 'e': 641, 'encodes': 631, 'domain': 612, 'potential': 611, 'large': 601, 'escherichia': 600, 'bacteria': 596, 'each': 596, 'rat': 590, 'clone': 588, 'strains': 577, 'bacterial': 575, 'orfs': 574, 'highly': 570, 'base': 568, 'kb': 564, 'single': 564, 'four': 557, 'respectively': 556, 'novel': 555, 'm': 551, 'data': 550, 'report': 550, 'among': 548, 'identical': 548, 'sequencing': 545, 'comparison': 543, 'results': 542, 'type': 541, 'encoded': 540, '1': 539, 'presence': 534, 'pairs': 533, 'deduced': 530, 'important': 528, 'used': 521, 'subunit': 513, 'transcription': 510, 'homologous': 510, 'alpha': 510, 'role': 503, 'there': 502, 'first': 502, 'peptide': 501, 'significant': 495, 'virulence': 492, 'well': 492, 'however': 491, 'number': 488, 'approximately': 486, 'genetic': 483, 'encode': 483, 'genomes': 477, 'identity': 473, '2': 473, 'frames': 472, 'major': 468, 'during': 467, 'some': 465, 'yeast': 464, 'cdnas': 461, 'can': 461, 'binding': 460, 'host': 455, 'suggest': 454, 'site': 454, 'frame': 453, 'system': 453, 'i': 452, 'complex': 451, 'such': 447, 'mitochondrial': 444, 'characterized': 443, 'cytochrome': 441, 'enzymes': 438, 'purified': 434, 'subunits': 429, 'located': 429, 'operon': 428, 'receptor': 428, 'containing': 423, 'library': 422, 'functional': 421, 'mutant': 419, 'promoter': 418, 'products': 417, 'polypeptide': 416, 'unique': 412, 'bacterium': 410, 'reported': 409, 'corresponding': 409, 'mammalian': 405, 'peptides': 403, 'functions': 401, 'structural': 399, 'fragment': 397, 'kda': 397, 'compared': 395, 'levels': 395, 'show': 393, 'small': 392, 'signal': 389, 'our': 388, 'plant': 385, 'common': 381, 'beta': 379, 'analyses': 378, 'suggests': 378, 'although': 375, 'organization': 370, 'elements': 369, 'contained': 366, 'they': 365, 'transport': 365, 'membrane': 365, 'differences': 365, 'shown': 364, 'ii': 363, 'disease': 363, 'suggesting': 361, 'growth': 361, 'domains': 359, 'tissues': 359, 'factors': 356, 'product': 356, 'form': 355, 'detected': 355, 'v': 353, 'shows': 352, 'kinase': 352, 'transfer': 351, 'features': 351, 'group': 351, 'pathogen': 351, 'p': 350, 'had': 348, 'size': 348, 'distinct': 347, 'n-terminal': 347, 'any': 345, 'based': 345, 'contain': 345, 'level': 344, 'required': 342, 'about': 342, 'd': 341, 'h': 340, '3': 338, 'regulatory': 338, 'replication': 336, 'observed': 336, 'evolution': 335, 'protein-coding': 334, 'thus': 334, 'liver': 332, '': 331, 'content': 330, 'order': 329, 'addition': 329, 'upstream': 329, 'closely': 328, 'chain': 327, 'through': 325, 'systems': 324, 'bacillus': 321, 'plasmid': 321, 'five': 318, 'associated': 318, 'could': 315, 'bovine': 315, 'same': 315, 'trna': 313, 'members': 312, 'study': 311, 'total': 310, 'when': 310, 'indicate': 310, 'factor': 310, 'indicating': 308, 'brain': 308, 'transcripts': 307, 'sites': 305, 'essential': 305, 'long': 305, 'hybridization': 304, 'organism': 302, 'studies': 302, 'polymerase': 300, 'specific': 300, 'orf': 299, 'very': 292, 'virus': 291, 'drosophila': 288, 'identify': 287, 'organisms': 286, 'phylogenetic': 285, 'various': 284, 'low': 284, 'evidence': 281, 'while': 281, 'indicates': 280, 'cerevisiae': 279, 'biosynthesis': 278, 'indicated': 278, 'contrast': 278, 'length': 276, 'include': 275, 'least': 275, 't': 275, 'additional': 275, 'clusters': 273, 'evolutionary': 272, 'development': 271, 'blot': 270, 'primary': 269, 'plasmids': 268, 'consists': 268, 'production': 267, 'polypeptides': 266, 'after': 266, 'assigned': 265, 'synthesis': 265, 'reveals': 265, 'derived': 264, 'control': 264, 'metabolic': 263, 'northern': 263, '4': 262, 'circular': 262, 'resistance': 262, \"5'\": 260, 'chromosomes': 258, 'regulation': 258, 'cluster': 257, 'extensive': 255, 'typhimurium': 255, 'likely': 255, 'arabidopsis': 254, 'against': 253, 'consistent': 253, 'multiple': 252, 'entire': 252, 'described': 251, 'second': 251, 'causes': 251, 'cloning': 251, 'responsible': 251, 'designated': 250, 'part': 250, 'mass': 249, 'mutants': 249, 'iii': 249, 'divergence': 248, 'member': 247, 'full-length': 247, 'six': 246, 'gamma': 246, 'whereas': 245, 'subtilis': 244, 'codon': 242, 'obtained': 242, 'mature': 242, 'transcriptional': 241, 'model': 241, 'l': 240, 'chromosomal': 239, 'metabolism': 237, 'insertion': 237, 'cycle': 237, 'families': 236, 'distribution': 235, 'intracellular': 234, 'translation': 233, 'higher': 233, 'class': 231, 'diverse': 230, 'dehydrogenase': 230, 'nucleotides': 230, 'demonstrated': 229, 'set': 229, 'unknown': 228, 'introns': 227, 'basis': 227, 'buchnera': 226, 'repeats': 224, 'mutations': 224, 'cause': 223, 'similarities': 221, 'relative': 221, 'transcript': 219, 'either': 219, 'plants': 219, 'composed': 217, 'variation': 217, 'humans': 215, 'recombinant': 214, 'components': 213, 'exons': 213, 'conservation': 212, 'degree': 212, 'locus': 212, 'appears': 211, 'structures': 211, 'saccharomyces': 209, '5': 209, 'close': 207, 'variety': 207, 'homologues': 203, 'rrna': 202, 'receptors': 202, 'g': 202, 'motif': 202, \"3'\": 201, 'further': 201, 'vitro': 201, 'ability': 199, 'forms': 199, 'active': 199, 'under': 199, 'appear': 198, 'probe': 198, 'databases': 197, 'pcr': 197, 'nuclear': 196, 'r': 196, 'synthase': 195, 'mutation': 195, 'candidate': 195, '10': 194, 'cellular': 194, 'precursor': 193, 'position': 192, 'pathways': 192, 'segment': 191, 'pair': 191, 'use': 191, '50': 190, 'reaction': 190, 'possible': 188, 'whole': 188, 'infections': 188, 'c-terminal': 187, 'tuberculosis': 187, 'transcribed': 187, 'deletion': 186, 'range': 185, 'so': 185, 'over': 185, 'initiation': 184, 'tissue': 184, 'aeruginosa': 184, 'analyzed': 183, 'suggested': 183, 'gc': 182, 'pattern': 182, 'induced': 181, 'pathogens': 181, 'groups': 180, 'pneumoniae': 180, 'pathway': 180, 'j': 180, 'mechanisms': 178, 'processes': 178, 'identification': 177, 'actin': 177, 'mapping': 177, 'confirmed': 177, 'available': 176, 'did': 176, 'islands': 176, 'therefore': 175, 'information': 175, 'surface': 175, 'aureus': 175, 'them': 174, 'properties': 174, 'recently': 173, 'mrnas': 173, 'weight': 172, 'comparative': 171, 'increased': 171, 'mechanism': 170, 'partial': 170, 'pseudomonas': 170, 'consensus': 170, 'cysteine': 170, 'together': 169, 'intron': 168, 'experiments': 168, 'caused': 168, 'comparisons': 167, 'extracellular': 167, 'antibodies': 167, 'pathogenicity': 167, '11': 166, 'diversity': 166, 'degrees': 166, 'repeat': 166, 'staphylococcus': 166, 'database': 165, 'far': 165, 'response': 165, '12': 165, 'approach': 164, 'symbiotic': 164, 'apparent': 164, 'salmonella': 164, 'provide': 164, 'muscle': 164, 'probably': 163, 'origin': 163, 'collection': 163, 'sp': 163, 'early': 163, '6': 162, 'findings': 162, 'n': 162, 'positions': 162, 'horizontal': 161, 'biological': 161, 'limited': 160, 'end': 160, 'overall': 160, 'conditions': 159, 'source': 159, 'exon': 159, 'secretion': 159, 'typical': 158, 'eight': 158, 'pathogenesis': 158, 'largest': 158, 'restriction': 158, 'molecule': 157, 'whose': 157, 'central': 157, 'provides': 157, 'normal': 157, 'isoforms': 157, 'another': 156, 'completely': 156, 'x': 156, 'eukaryotic': 155, 'rate': 155, 'infection': 155, 'molecules': 155, 'characterization': 155, 'downstream': 154, 'loss': 154, 'result': 154, 'aa': 153, 'short': 153, 'methods': 153, 'agent': 152, 'formation': 152, 'start': 152, 'represents': 152, 'substitutions': 152, 'fragments': 151, 'organized': 150, 'localized': 150, 'map': 150, 'chicken': 150, 'remaining': 149, 'catalytic': 149, 'carbon': 148, 'phenotype': 148, 'strongly': 148, 'produced': 147, 'isolation': 146, 'mapped': 146, 'adult': 146, '100': 145, 'nt': 145, 'recent': 144, 'transmembrane': 144, 'mr': 143, 'physical': 143, 'chloroplast': 143, 'activation': 143, 'shared': 142, 'includes': 142, 'seven': 142, 'strong': 142, 'murine': 141, '20': 139, 'genus': 139, 'complementary': 139, 'represent': 139, 'understanding': 139, '30': 138, 'third': 138, 'residue': 138, 'recombination': 138, 'might': 138, 'antigen': 138, 'furthermore': 138, 'kidney': 138, 'clustered': 138, 'because': 138, '7': 138, 'pathogenic': 137, 'portion': 137, 'does': 137, 'repetitive': 137, 'mycobacterium': 137, 'million': 137, 'around': 136, 'gram-positive': 136, 'almost': 136, 'basic': 136, 'larger': 136, 'mb': 136, 'isolates': 136, 'wild-type': 136, 'missing': 136, '13': 135, 'nitrogen': 135, 'xenopus': 135, 'isolate': 135, 'search': 135, 'pylori': 135, 'public': 134, 'events': 134, 'will': 134, 'highest': 134, 'hydrophobic': 134, 'lack': 134, 'absent': 133, 'leading': 133, 'constructed': 133, 'like': 133, 'increase': 133, 'half': 132, 'meliloti': 132, 'component': 132, 'regulated': 132, 'examined': 132, 'secondary': 132, 'linked': 131, 'resulting': 131, 'copies': 131, '60': 131, 'vivo': 131, 'element': 131, 'years': 130, 'motifs': 130, 'describe': 130, 'southern': 130, 'key': 130, 'lateral': 130, '80': 129, 'duplication': 129, 'assembly': 129, 'delta': 129, 'generated': 129, 'comprises': 128, 'atcc': 128, 'melanogaster': 128, 'unusual': 127, 'differentiation': 127, 'demonstrate': 127, 'splicing': 127, 'terminus': 127, 'cholerae': 127, 'biosynthetic': 127, 'gram-negative': 127, 'majority': 126, 'average': 126, 'homologue': 126, 'now': 126, 'mgc': 126, 'jannaschii': 125, 'significantly': 125, 'degradation': 125, 'annotation': 125, 'extension': 125, 'toxin': 125, 'being': 125, 'less': 124, 'established': 124, 'biology': 123, 'thaliana': 123, 'previous': 123, 'archaea': 122, 'archaeal': 122, 'mammals': 122, 'animal': 122, 'alternative': 122, 'possibly': 122, 'serovar': 121, 'proposed': 121, 'step': 121, 'libraries': 121, 'cyclin': 121, 'island': 120, 'et': 120, 'play': 120, 'since': 120, 'representing': 120, 'reduced': 120, 'codons': 120, 'homologs': 119, 'al': 119, 'exhibited': 119, 'where': 119, 'full': 118, 'environmental': 118, 'eukaryotes': 118, 'cytoplasmic': 118, 'interaction': 118, '22': 118, 'reductase': 118, 'tree': 117, 'contribute': 117, 'absence': 117, 'fastidiosa': 117, 'called': 116, 'kilobases': 116, 'supported': 116, 'named': 116, 'throughout': 116, 'antibiotics': 116, '27': 115, 'mtdna': 115, '25': 115, 'few': 115, 'changes': 115, 'due': 114, 'synthesized': 114, 'resulted': 114, '16': 114, 'nearly': 114, 'f': 114, '17': 114, 'alleles': 114, 'interactions': 113, '24': 113, 'obligate': 113, 'effect': 113, 'atp': 113, 'activities': 113, '70': 113, 'consisting': 113, '18': 112, '42': 112, 'atpase': 112, 'except': 112, 'probes': 112, 'composition': 111, 'substrate': 111, 'elegans': 111, 'heart': 111, 'operons': 110, 'yet': 110, 'codes': 110, 'striking': 110, 'extracts': 110, 'direct': 110, '8': 110, 'vertebrate': 110, 'oxidase': 109, 'support': 109, 'free-living': 109, 'specificity': 109, 'microbial': 109, 'influenzae': 109, 'lines': 109, 'typhi': 109, 'characteristic': 109, 'per': 109, 'date': 108, 'homolog': 108, 'near': 108, 'calculated': 108, 'differs': 108, 'fusion': 108, 'shotgun': 107, 'phosphorylation': 107, 'point': 107, 'pig': 107, 'rnas': 107, 'subfamily': 107, 'lt2': 107, 'necessary': 106, 'occurred': 106, 'o157h7': 106, 'energy': 106, 'diseases': 106, 'transporters': 106, 'location': 105, 'campestris': 105, 'wide': 105, 'presented': 105, 'implicated': 105, 'characteristics': 105, 'lambda': 105, 'rabbit': 105, 'adjacent': 104, 'primer': 104, 'toxins': 104, 'occur': 103, 'electron': 103, 'pombe': 103, 'classes': 103, 'followed': 103, 'discussed': 103, 'situ': 103, 'share': 103, 'code': 103, 'adaptation': 102, 'cases': 102, 'xanthomonas': 102, 'channel': 102, 'without': 102, 'medium': 101, 'little': 100, '15': 100, 'exhibit': 100, 'gel': 100, 'lineages': 100, 'inhibitor': 100, 'syndrome': 100, 'propose': 99, 'segments': 99, 'rearrangements': 99, 'loci': 99, 'relationships': 99, 'secreted': 99, 'affinity': 99, 'then': 99, 'even': 98, 'line': 98, 'transition': 98, 'respiratory': 98, 'separated': 98, 'hypothetical': 97, 'primers': 97, 'effort': 97, 'induction': 97, 'repeated': 97, 'roles': 96, 'serine': 96, 'distributed': 96, 'iron': 96, 'developmental': 96, 'da': 96, '19': 95, 'regulator': 95, '14': 95, 'studied': 95, 'capacity': 95, 'antibody': 95, 'apparently': 95, 'existence': 95, 'newly': 95, '38': 95, 'types': 95, 'ph': 95, 'lacks': 94, 'differ': 94, 'difference': 94, 'light': 94, 'screening': 94, 'chronic': 94, '21': 94, 'promoters': 94, 'outer': 93, 'flanking': 93, 'amplified': 93, 'cleavage': 93, 'photosynthetic': 93, 'acquisition': 93, 'potentially': 92, 'lower': 92, 'abundant': 92, 'uptake': 92, 'fever': 92, 'protease': 92, 'parahaemolyticus': 92, 'time': 91, 'along': 91, 'percent': 91, '40': 91, 'mitochondria': 91, 'complementation': 91, 'ec': 91, 'copy': 91, 'relatively': 90, 'acquired': 90, 'processing': 90, 'alignment': 90, 'motility': 90, 'despite': 90, 'cancer': 90, 'rates': 90, 'sigma': 89, 'worldwide': 89, 'native': 89, 'exhibits': 89, 'tyrosine': 89, 'shares': 89, 'arrangement': 89, 'numerous': 89, 'maps': 89, 'functionally': 89, 'relationship': 89, 'eucaryal': 88, 'division': 88, 'included': 88, 'kinases': 88, 'ribosomal': 88, 'complement': 88, 'determine': 88, 'testis': 88, 'moreover': 88, 'enterica': 88, 'via': 88, 'environment': 87, 'whole-genome': 87, '28': 87, 'do': 87, 'bias': 87, 'bind': 87, 'overlapping': 87, 'reduction': 87, 'binds': 87, 'capable': 87, 'initial': 87, 'detection': 87, 'iv': 87, 'independent': 87, 'thermophilic': 86, '36': 86, 'general': 86, 'strain-specific': 86, 'process': 86, 'stress': 86, 'proportion': 86, 'directly': 86, 'laboratory': 86, 'streptomyces': 86, 'late': 86, 'amplification': 86, 'skeletal': 86, 'mrsa': 86, 'following': 86, 'life': 86, '90': 85, 'feature': 85, 'target': 85, 'transduction': 85, 'survival': 85, 'termed': 85, 'patterns': 85, 'project': 85, 'african': 85, 'streptococcus': 85, 'method': 85, 'isoform': 85, 'k': 85, '46': 84, 'phenotypes': 84, 'strategy': 84, 'termination': 84, 'represented': 84, 'sets': 84, 'lung': 84, 'accumulation': 84, 'restricted': 84, 'nature': 84, 'treatment': 84, 'useful': 84, 'symbiont': 84, 'full-orf': 84, 'individual': 84, '29': 83}\n"
     ]
    }
   ],
   "source": [
    "f = open(\"trg.csv\", \"r\")\n",
    "\n",
    "#The frequency of all words\n",
    "freq = {}\n",
    "\n",
    "#A list of the top 1000 most common words\n",
    "best = []\n",
    "\n",
    "#The frequency top 1000 most common words, beucase I remove them from freq later\n",
    "total = {}\n",
    "\n",
    "#Go through each line and \n",
    "for line in f:\n",
    "    #Get each column\n",
    "    cols = line.split(\",\")\n",
    "    #Remove some leftover junk from the csv file\n",
    "    cols[2] = cols[2].strip(\"\\n\")\n",
    "    cols[2] = cols[2].strip('\"')\n",
    "    \n",
    "    #Spilt the test column into individual words\n",
    "    words = cols[2].split(\" \")\n",
    "    \n",
    "    #For each word add it's frequency to freq\n",
    "    for word in words:\n",
    "        if(word in freq):\n",
    "            freq[word] = freq[word] + 1\n",
    "        else:\n",
    "            freq[word] = 1\n",
    "\n",
    "#Get top 1000 words\n",
    "for x in range(1000):\n",
    "    best.append(max(freq.keys(), key=(lambda k: freq[k])))\n",
    "    total[best[-1]] = freq[best[-1]]\n",
    "    freq.pop(best[-1])\n",
    "\n",
    "print(\"{} ... {}\".format(best[:5], best[-5:]))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-dream",
   "metadata": {},
   "source": [
    "### Process the data to get frequncey tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "figured-output",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id' 'class' 'the' ... 'full-orf' 'individual' '29']\n",
      " ['1' 'B' '12' ... '0' '0' '1']\n",
      " ['2' 'A' '25' ... '0' '0' '0']\n",
      " ...\n",
      " ['3998' 'E' '15' ... '0' '0' '0']\n",
      " ['3999' 'E' '16' ... '0' '0' '0']\n",
      " ['4000' 'B' '10' ... '0' '0' '0']]\n"
     ]
    }
   ],
   "source": [
    "#Reimport the csv to make sure nothing has changed.\n",
    "f = open(\"trg.csv\", \"r\")\n",
    "\n",
    "data = []\n",
    "#Now that the top 1000 words is know, we can go through and make a big array with the frequency of each word for each row\n",
    "for line in f:\n",
    "    #Same processing as before\n",
    "    cols = line.split(\",\")\n",
    "    cols[2] = cols[2][1:-2]\n",
    "    cols[2] = cols[2].strip(\"\\n\")\n",
    "    cols[2] = cols[2].strip('\"')\n",
    "    words = cols[2].split(\" \")\n",
    "    cols = cols[:-1]\n",
    "    \n",
    "    #Counter gets the fequency of words in the array\n",
    "    freqForRow = Counter(words)\n",
    "    \n",
    "    if(cols[0] == 'id'):\n",
    "        #Get a row for headers\n",
    "        cols += best\n",
    "    else:\n",
    "        for word in best:\n",
    "            if word in words:\n",
    "                cols.append(int(freqForRow[word]))\n",
    "            else:\n",
    "                cols.append(0)\n",
    "        \n",
    "        \n",
    "    data.append(cols)\n",
    "    \n",
    "\n",
    "processedData = np.array(data)\n",
    "print(processedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-syndication",
   "metadata": {},
   "source": [
    "### Split data in 5 random groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 1234\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "datasplit = [[],[],[],[],[]]\n",
    "\n",
    "#For every row, randomly put it in one of the groups\n",
    "for ele in processedData[1:]:#The split data doesn't have headers\n",
    "    datasplit[np.random.randint(0, 5)].append(ele)\n",
    "        \n",
    "datasplit = np.array(datasplit)\n",
    "\n",
    "for ele in datasplit:\n",
    "    print(len(ele))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-functionality",
   "metadata": {},
   "source": [
    "### Simple Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-laugh",
   "metadata": {},
   "source": [
    "I started with making the simple Naive Bayes algorithm as described in the lecture. I needed to log the probability before summing them because otherwise, it would underflow. This implementation also has cross-validation to check accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['A', 'B', 'E', 'V'] #0:A, 1:B, 2:E, 3:V\n",
    "score = np.zeros(len(datasplit))\n",
    "\n",
    "#For all five validation groups\n",
    "for w in range(len(datasplit)):\n",
    "    #classnum is the amount of classes\n",
    "    classnum = [0,0,0,0]\n",
    "    #classtotal is the total amount of words in a class\n",
    "    classtotal = [0,0,0,0]\n",
    "    #byclass is so I can look up how many times a word appears in a class\n",
    "    byClass = dict((el,[0,0,0,0]) for el in best)\n",
    "    \n",
    "    test = []\n",
    "    train = []\n",
    "    #Creat train and test using split data from before\n",
    "    for z in range(len(datasplit)):\n",
    "        if(z == w):\n",
    "            test = datasplit[z].copy()\n",
    "        else:\n",
    "            train += datasplit[z].copy()\n",
    "            \n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    \n",
    "    for ele in train:\n",
    "        eleClass = classes.index(ele[1])\n",
    "        classnum[eleClass] += 1\n",
    "        for i in range(2, len(ele)):\n",
    "            classtotal[eleClass] += int(ele[i])\n",
    "            byClass[data[0][i]][eleClass] += int(ele[i])\n",
    "            \n",
    "    correct = 0\n",
    "\n",
    "    #for each row in test\n",
    "    for ele in test:\n",
    "        #classProbs stores the probability that a row is a class\n",
    "        classProbs = np.zeros(4)\n",
    "        \n",
    "        #For the number of classes this row could be (4)\n",
    "        for i in range(4):\n",
    "            #Initialize the probablity to be the log of the amount this class occurs over all classes occurring\n",
    "            classProbs[i] = math.log(classnum[0] / len(train))\n",
    "            \n",
    "            #For every word in the top 1000\n",
    "            for j in range(2, len(ele)):\n",
    "                #If this word appears in the row\n",
    "                if float(ele[j]) > 0 :\n",
    "                    #The count of this word in this class smoothed with 1\n",
    "                    countWC = (int(byClass[data[0][j]][i]) + 1)\n",
    "                    #The count of this class smoothed with the number of words (1000)\n",
    "                    countCV = (int(classtotal[i]) + len(best))\n",
    "                    \n",
    "                    #The probility of this word occuring in this class, to the power of the number of times it occurs in this row\n",
    "                    probofword = math.pow((countWC/countCV), float(ele[j]))\n",
    "                    \n",
    "                    #Incease the total probability it's this class (added because everything is a log)\n",
    "                    classProbs[i] = classProbs[i] + math.log(probofword)\n",
    "        \n",
    "        #Get the best guess and check if it's right.\n",
    "        if(classes[np.argmax(classProbs)] == ele[1]):\n",
    "            correct += 1\n",
    "    \n",
    "    score[w] = (correct/len(test))\n",
    "    print(\"Score of fold {}: {:.4f}\".format(w+1, score[w]))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Mean Score: {:.4f}\".format(score.mean()))\n",
    "print(\"Standard divaiation: {:.4f}\".format(score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-blocking",
   "metadata": {},
   "source": [
    "This did alright. It gets about 89% during the cross-validation which is much better than random but not the best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-rider",
   "metadata": {},
   "source": [
    "### First modification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-conservative",
   "metadata": {},
   "source": [
    "My first modification to the algorithm I was trying to account for the fact that classes in the training data set are distributed very unevenly. To do this I implemented the modifications outlined in section 3.1 of Tackling the Poor Assumptions of Naive Bayes Text Classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['A', 'B', 'E', 'V'] #0:A, 1:B, 2:E, 3:V\n",
    "score = np.zeros(len(datasplit))\n",
    "\n",
    "#For all five validation groups\n",
    "for w in range(len(datasplit)):\n",
    "    #classnum is the amount of classes\n",
    "    classnum = [0,0,0,0]\n",
    "    #classtotal is the total amount of words in a class\n",
    "    classtotal = [0,0,0,0]\n",
    "    #byclass is so I can look up how many times a word appears in a class\n",
    "    byClass = dict((el,[0,0,0,0]) for el in best)\n",
    "    \n",
    "    test = []\n",
    "    train = []\n",
    "    #Creat train and test using split data from before\n",
    "    for z in range(len(datasplit)):\n",
    "        if(z == w):\n",
    "            test = datasplit[z].copy()\n",
    "        else:\n",
    "            train += datasplit[z].copy()\n",
    "            \n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    \n",
    "    for ele in train:\n",
    "        eleClass = classes.index(ele[1])\n",
    "        classnum[eleClass] += 1\n",
    "        for i in range(2, len(ele)):\n",
    "            classtotal[eleClass] += int(ele[i])\n",
    "            byClass[data[0][i]][eleClass] += int(ele[i])\n",
    "            \n",
    "\n",
    "    correct = 0\n",
    "\n",
    "    #for each row in test\n",
    "    for ele in test:\n",
    "        #classProbs stores the probability that a row is a class\n",
    "        classProbs = np.zeros(4)\n",
    "        \n",
    "        #For the number of classes this row could be (4)\n",
    "        for i in range(4):\n",
    "            #Initialize the probablity to be the log of the amount this class occurs over all classes occurring. \n",
    "            classProbs[i] = math.log(classnum[0] / len(train))\n",
    "            \n",
    "            #For every word in the top 1000\n",
    "            for j in range(2, len(ele)):\n",
    "                #If this word appears in the row\n",
    "                if float(ele[j]) > 0 :\n",
    "                    #otherWC is the number of times a word occurs in a different class to the current\n",
    "                    otherWC = 1\n",
    "                    #otherCV is the total number of occurrences of different class to the current\n",
    "                    otherCV = len(best)\n",
    "                    \n",
    "                    #If its the current class, update countWC and countCV, if it's not update otherWC and otherCV\n",
    "                    for x in range(4):\n",
    "                        if(x == i):\n",
    "                            countWC = (int(byClass[data[0][j]][i]) + 1)\n",
    "                            countCV = (int(classtotal[i]) + len(best))\n",
    "                        else:\n",
    "                            otherWC += byClass[data[0][j]][x]\n",
    "                            otherCV += classtotal[x]\n",
    "                            \n",
    "                    #This time the probility it's in this class is over the probabilty it's in a different class\n",
    "                    probofword = math.pow(((countWC/countCV)/(otherWC/otherCV)), float(ele[j]))\n",
    "                    #Incease the total probability it's this class (added because everything is a log)\n",
    "                    classProbs[i] = classProbs[i] + math.log(probofword)\n",
    "                    \n",
    "        #Get the best guess and check if it's right.\n",
    "        if(classes[np.argmax(classProbs)] == ele[1]):\n",
    "            correct += 1\n",
    "            \n",
    "    score[w] = (correct/len(test))\n",
    "    print(\"Score of fold {}: {:.4f}\".format(w+1, score[w]))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Mean Score: {:.4f}\".format(score.mean()))\n",
    "print(\"Standard divaiation: {:.4f}\".format(score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-statistics",
   "metadata": {},
   "source": [
    "This worked quite well with an increase in accuracy of about 2 percentage points. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-mainstream",
   "metadata": {},
   "source": [
    "### Second modification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-maximum",
   "metadata": {},
   "source": [
    "For the second extension, I tried to account for words like \"the\" that appear many times in all rows. I did this by implementing section 4.2 of Tackling the Poor Assumptions of Naive Bayes Text Classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['A', 'B', 'E', 'V'] #0:A, 1:B, 2:E, 3:V\n",
    "score = np.zeros(len(datasplit))\n",
    "\n",
    "#For all five validation groups\n",
    "for w in range(len(datasplit)):\n",
    "    #classnum is the amount of classes\n",
    "    classnum = [0,0,0,0]\n",
    "    #classtotal is the total amount of words in a class\n",
    "    classtotal = [0,0,0,0]\n",
    "    #byclass is so I can look up how many times a word appears in a class\n",
    "    byClass = dict((el,[0,0,0,0]) for el in best)\n",
    "    #Occurs is the number of rows a words appares in\n",
    "    occurs = np.zeros(1000)\n",
    "    \n",
    "    test = []\n",
    "    train = []\n",
    "    #Creat train and test using split data from before\n",
    "    for z in range(len(datasplit)):\n",
    "        if(z == w):\n",
    "            test = datasplit[z].copy()\n",
    "        else:\n",
    "            train += datasplit[z].copy()\n",
    "            \n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    \n",
    "    for ele in train:\n",
    "        eleClass = classes.index(ele[1])\n",
    "        classnum[eleClass] += 1\n",
    "        for i in range(2, len(ele)):\n",
    "            classtotal[eleClass] += int(ele[i])\n",
    "            byClass[data[0][i]][eleClass] += int(ele[i])\n",
    "            if(int(ele[i]) > 0):\n",
    "                occurs[i-2] += 1\n",
    "            \n",
    "    correct = 0\n",
    "\n",
    "    #for each row in test\n",
    "    for ele in test:\n",
    "        #classProbs stores the probability that a row is a class\n",
    "        classProbs = np.zeros(4)\n",
    "        \n",
    "        #For the number of classes this row could be (4)\n",
    "        for i in range(4):\n",
    "            #Initialize the probablity to be the log of the amount this class occurs over all classes occurring. \n",
    "            classProbs[i] = math.log(classnum[0] / len(train))\n",
    "            \n",
    "            #For every word in the top 1000\n",
    "            for j in range(2, len(ele)):\n",
    "                #If this word appears in the row\n",
    "                if float(ele[j]) > 0 :\n",
    "                    #otherWC is the number of times a word occurs in a different class to the current\n",
    "                    otherWC = 1\n",
    "                    #otherCV is the total number of occurrences of different class to the current\n",
    "                    otherCV = len(best)\n",
    "                    \n",
    "                    #If its the current class, update countWC and countCV, if it's not update otherWC and otherCV\n",
    "                    for x in range(4):\n",
    "                        if(x == i):\n",
    "                            #Transforming by document frequency of this word\n",
    "                            countWC = (int(byClass[data[0][j]][i]) + 1) * math.log(len(train)/occurs[j-2])\n",
    "                            countCV = (int(classtotal[i]) + len(best))\n",
    "                        else:\n",
    "                            #Transforming by document frequency of this word\n",
    "                            otherWC += byClass[data[0][j]][x] * math.log(len(train)/occurs[j-2])\n",
    "                            otherCV += classtotal[x]\n",
    "\n",
    "                    #Same as before\n",
    "                    probs = math.pow(((countWC/countCV)/(otherWC/otherCV)), float(ele[j]))\n",
    "                    classProbs[i] = classProbs[i] + math.log(probs)\n",
    "                    \n",
    "                    \n",
    "        #Get the best guess and check if it's right.\n",
    "        if(classes[np.argmax(classProbs)] == ele[1]):\n",
    "            correct += 1\n",
    "            \n",
    "    score[w] = (correct/len(test))\n",
    "    print(\"Score of fold {}: {:.4f}\".format(w+1, score[w]))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Mean Score: {:.4f}\".format(score.mean()))\n",
    "print(\"Standard divaiation: {:.4f}\".format(score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-recovery",
   "metadata": {},
   "source": [
    "The effect of this change is very small with how I've implemented it at less than 1 percentage points which at how small it is could be due to randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-method",
   "metadata": {},
   "source": [
    "## Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-analyst",
   "metadata": {},
   "source": [
    "Below is the code I used to get an output I could use for kaggle. I use the whole training set instead of just 4/5ths of it so the score on kaggle is slightly higher than that of any of my validations. It's using the algorithm with both modifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "european-association",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id' 'the' 'of' ... 'full-orf' 'individual' '29']\n",
      " ['1' '10' '9' ... '0' '0' '0']\n",
      " ['2' '6' '7' ... '0' '0' '0']\n",
      " ...\n",
      " ['998' '8' '10' ... '0' '0' '0']\n",
      " ['999' '7' '6' ... '0' '0' '0']\n",
      " ['1000' '24' '16' ... '0' '0' '0']]\n"
     ]
    }
   ],
   "source": [
    "f = open(\"tst.csv\", \"r\")\n",
    "data = []\n",
    "for line in f:\n",
    "    cols = line.split(\",\")\n",
    "    cols[1] = cols[1][1:-2]\n",
    "    words = cols[1].split(\" \")\n",
    "    cols = cols[:-1]\n",
    "    freq = Counter(words)\n",
    "    if(cols[0] == 'id'):\n",
    "        cols += best\n",
    "    else:\n",
    "        for word in best:\n",
    "            if word in words:\n",
    "                cols.append(freq[word])\n",
    "            else:\n",
    "                cols.append(0)\n",
    "        \n",
    "        \n",
    "    data.append(cols)\n",
    "    \n",
    "\n",
    "testData = np.array(data)\n",
    "print(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "toxic-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['A', 'B', 'E', 'V'] #0:A, 1:B, 2:E, 3:V\n",
    "\n",
    "#classnum is the amount of classes\n",
    "classnum = [0,0,0,0]\n",
    "#classtotal is the total amount of words in a class\n",
    "classtotal = [0,0,0,0]\n",
    "#byclass is so I can look up how many times a word appears in a class\n",
    "byClass = dict((el,[0,0,0,0]) for el in best)\n",
    "#Occurs is the number of rows a words appares in\n",
    "occurs = np.zeros(1000)\n",
    "\n",
    "for ele in processedData[1:]:\n",
    "    eleClass = classes.index(ele[1])\n",
    "    classnum[eleClass] += 1\n",
    "    for i in range(2, len(ele)):\n",
    "        classtotal[eleClass] += int(ele[i])\n",
    "        byClass[processedData[0][i]][eleClass] += int(ele[i])\n",
    "        if(int(ele[i]) > 0):\n",
    "            occurs[i-2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "logical-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['A', 'B', 'E', 'V']\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for ele in testData[1:]:\n",
    "    cat = np.zeros(4)\n",
    "    for i in range(4):\n",
    "            cat[i] = math.log(classnum[0] / len(processedData))\n",
    "    for i in range(4):\n",
    "        for j in range(2, len(ele)):\n",
    "            if float(ele[j]) > 0:\n",
    "                otherWC = 1\n",
    "                otherCV = len(best)\n",
    "                \n",
    "                for x in range(4):\n",
    "                    if(x == i):\n",
    "                        countWC = (int(byClass[data[0][j]][i]) + 1) * math.log(len(processedData)/occurs[j-2])\n",
    "                        countCV = (int(classtotal[i]) + len(best))\n",
    "                    else:\n",
    "                        otherWC += byClass[data[0][j]][x] * math.log(len(processedData)/occurs[j-2])\n",
    "                        otherCV += classtotal[x]\n",
    "\n",
    "            \n",
    "                probs = math.pow(((countWC/countCV)/(otherWC/otherCV)), float(ele[j]))\n",
    "                cat[i] = cat[i] + math.log(probs)\n",
    "        \n",
    "    predictions.append(classes[np.argmax(cat)])\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "durable-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predictions.csv', mode='w', newline='') as csv_file:\n",
    "    headers = ['id', 'class']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=headers)\n",
    "    writer.writerow({'id':'id', 'class':'class'})\n",
    "    for i in range(len(predictions)):\n",
    "        writer.writerow({'id':i+1, 'class':predictions[i]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
